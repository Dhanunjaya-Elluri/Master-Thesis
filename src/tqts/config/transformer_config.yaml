# Config file for the transformer model

# Model parameters
model:
    vocab_size: 12
    d_model: 128
    num_heads: 4
    num_encoder_layers: 3
    num_decoder_layers: 3
    dim_feedforward: 512
    dropout: 0.1
    activation: 'relu'
    pad_idx: 0

# dataset parameters
data:
    file_path: 'data/alphabets_with_lloyd_no_trend.txt'
    batch_size: 32
    seq_len: 10
    split_ratio: 0.8

# training parameters
training:
    epochs: 50
    log_interval: 2
    log_dir: 'logs'
    save_dir: 'checkpoints'

# optimizer parameters
optimizer:
    lr: 0.001
